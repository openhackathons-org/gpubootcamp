{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Previous Notebook](token-classification-deployment.ipynb)\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&ensp;\n",
    "[Home Page](../START_HERE_RIVA_BOOTCAMP.ipynb)\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;\n",
    "[1](token-classification-training.ipynb)\n",
    "[2](token-classification-deployment.ipynb)\n",
    "[3]\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a Named Entity Recognition Model in Riva - Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook explores taking an .riva model, the result of `tlt token_classification` command, and leveraging the Riva ServiceMaker framework to aggregate all the necessary artifacts for Riva deployment to a target environment. Once the model is deployed in Riva, you can issue inference requests to the server. . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "In this notebook, you will learn how to:  \n",
    "- Deploy the model(s) locally  on the Riva Server\n",
    "- Send inference requests using the Riva Python API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To follow along, please make sure:\n",
    "- You have access to NVIDIA NGC, and are able to download the Riva Quickstart [resources](https://ngc.nvidia.com/catalog/resources/nvidia:riva:riva_quickstart)\n",
    "- Have an .riva model file that you wish to deploy. You can obtain this from `tlt <task> export` (with `export_format=RIVA`). Please refer the tutorial on *Named entity recognition using Transfer Learning Toolkit* for more details on training and exporting an .riva model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Inference\n",
    "Once the Riva server is up and running with your models, you can send inference requests querying the server. \n",
    "\n",
    "To send GRPC requests, you can install Riva Python API bindings for client. This is available as a pip .whl with the QuickStart.\n",
    "\n",
    "Otherwise, you can use the riva-client docker container which comes pre-installed with all the inference dependancies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Riva server and run inference\n",
    "Now we actually query the Riva server, let's get started. The following cell queries the riva server(using grpc) to yield a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $RIVA_DIR/ner_client.py\n",
    "\n",
    "import grpc\n",
    "import os\n",
    "import argparse\n",
    "import riva_api.riva_nlp_pb2 as rnlp\n",
    "import riva_api.riva_nlp_pb2_grpc as rnlp_srv\n",
    "\n",
    "# use the NER network to return top-1 classes for entities\n",
    "def postprocess_labels_server(tokens_response):\n",
    "    results = []\n",
    "    for i in range(0, len(tokens_response.results)):\n",
    "        slots = []\n",
    "        slot_scores = []\n",
    "        tokens = []\n",
    "        for j in range(0, len(tokens_response.results[i].results)):\n",
    "          entity = tokens_response.results[i].results[j]\n",
    "          tokens.append(entity.token)\n",
    "          slots.append(entity.label[0].class_name)\n",
    "          slot_scores.append(entity.label[0].score)\n",
    "        results.append((slots, tokens, slot_scores))\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_ner(grpc_server, query):\n",
    "    channel = grpc.insecure_channel(grpc_server)\n",
    "    riva_nlp = rnlp_srv.RivaLanguageUnderstandingStub(channel)\n",
    "    req = rnlp.AnalyzeEntitiesRequest()\n",
    "    req.query = query\n",
    "    resp = riva_nlp.AnalyzeEntities(req)\n",
    "    print(\"Query:\", query)\n",
    "    print(postprocess_labels_server(resp))\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Client app to test named entity recognition on Riva\")\n",
    "    parser.add_argument(\"--server\", default=\"localhost:50051\", type=str, help=\"URI to GRPC server endpoint\")\n",
    "    parser.add_argument(\"--query\", default=\"NVIDIA is located at Santa Clara\", type=str, help=\"Input Query\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "def run_ner_client():\n",
    "    args = get_args()\n",
    "    run_ner(args.server, query=args.query)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_ner_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've installed the Riva Python API bindings for client using the pip whl, you can execute the above saved script with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3 $RIVA_DIR/ner_client.py --query \"NVIDIA is located at Santa Clara\" --server localhost:50051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Token Classification Inference using the Riva Python API directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run Named Entity Recognition using the API directly without executing client side scripts.\n",
    "An example is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import require libraries\n",
    "import io\n",
    "import librosa\n",
    "from time import time\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "import requests\n",
    "\n",
    "# NLP proto\n",
    "##change this configuration to match your DGX number and your RIVA port number\n",
    "##for example, 'dgx0180:50055'\n",
    "\n",
    "channel = grpc.insecure_channel('localhost:50051')\n",
    "\n",
    "import riva_api.riva_nlp_pb2 as rnlp\n",
    "import riva_api.riva_nlp_pb2_grpc as rnlp_srv\n",
    "\n",
    "\n",
    "riva_nlp = rnlp_srv.RivaLanguageUnderstandingStub(channel)\n",
    "\n",
    "\n",
    "\n",
    "# Use the TokenClassification API to run a Named Entity Recognition (NER) model\n",
    "# Note: the model configuration of the NER model indicates that the labels are\n",
    "# in IOB format. Riva, subsequently, knows to:\n",
    "#   a) ignore 'O' labels\n",
    "#   b) Remove B- and I- prefixes from labels\n",
    "#   c) Collapse sequences of B- I- ... I- tokens into a single token\n",
    "\n",
    "req = rnlp.TokenClassRequest()\n",
    "req.model.model_name = \"riva_ner\"     # If you have deployed a custom model with the domain_name \n",
    "                                        # parameter in ServiceMaker's `riva-build` command then you should use \n",
    "                                        # \"riva_ner_<your_input_domain_name>\" where <your_input_domain_name>\n",
    "                                        # is the name you provided to the domain_name parameter.\n",
    "\n",
    "req.text.append(\"Jensen Huang is the CEO of NVIDIA Corporation, \"\n",
    "                \"located in Santa Clara, California\")\n",
    "resp = riva_nlp.ClassifyTokens(req)\n",
    "\n",
    "print(\"Named Entities:\")\n",
    "for result in resp.results[0].results:\n",
    "    print(f\"  {result.token} ({result.label[0].class_name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise :\n",
    "\n",
    "Use the Token classification API to identify Named Entities in the following sentences\n",
    "Note: you may use the client python file to compare your result against the model you choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: \"The weather in New York today is much hotter than in San Francisco.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: \"The Sahara desert is located in Africa.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: \"The Amazon rainforest is being affected by climate change.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##first, import the required libraries\n",
    "\n",
    "import io\n",
    "import librosa\n",
    "from time import time\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "import requests\n",
    "\n",
    "# NLP proto\n",
    "\n",
    "\n",
    "## next, setup the connection parameters and variables\n",
    "## next, initialize the query variables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the TokenClassification API to run a Named Entity Recognition (NER) model\n",
    "# Note: the model configuration of the NER model indicates that the labels are\n",
    "# in IOB format. Jarvis, subsequently, knows to:\n",
    "#   a) ignore 'O' labels\n",
    "#   b) Remove B- and I- prefixes from labels\n",
    "#   c) Collapse sequences of B- I- ... I- tokens into a single token\n",
    "\n",
    "## initialize the request object\n",
    "\n",
    "\n",
    "\n",
    "##setup the query\n",
    "\n",
    "\n",
    "##make the request\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##parse the response variable and print out the entities found \n",
    "\n",
    "\n",
    "## compare results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
