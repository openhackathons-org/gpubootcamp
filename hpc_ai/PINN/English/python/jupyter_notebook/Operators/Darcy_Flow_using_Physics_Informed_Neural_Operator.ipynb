{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10136b3e",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e3bff",
   "metadata": {},
   "source": [
    "In this notebook we will introduce the brief theory behind the Physics Informed Neural Operators (PINO) and use them to solve the same data-driven Darcy flow problem that was introduced in the [FNO notebook](Darcy_Flow_using_Fourier_Neural_Operators.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053f3f9",
   "metadata": {},
   "source": [
    "### Learning Outcomes\n",
    "1. How to setup and train PINO in Modulus\n",
    "2. Defining a custom PDE constraint for grid data\n",
    "3. Differences between PINO and FNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e084e",
   "metadata": {},
   "source": [
    "## PINO Theory\n",
    "\n",
    "The Physics-Informed Neural Operator (PINO) was introduced by Li et al. in the [paper](https://arxiv.org/abs/2111.03794). The PINO approach for surrogate modeling of PDE systems effectively combines the data-informed supervised learning framework of the FNO with the physics-informed learning framework. The PINO incorporates a PDE loss $\\mathcal{L}_{pde}$ to the Fourier Neural Operator. This reduces the amount of data required to train a surrogate model, since the PDE loss constrains the solution space. \n",
    "The PDE loss also enforces physical constraints on the solution computed by a surrogate ML model, making it an attractive option as a verifiable, accurate and interpretable ML surrogate modeling tool.\n",
    "\n",
    "We consider a stationary PDE system for simplicity, although the PINO method can be applied to dynamical systems as well. \n",
    "Following the notation used in the [paper](https://arxiv.org/abs/2111.03794), we consider a PDE represented by,\n",
    "\n",
    "\\begin{equation} \n",
    "\\mathcal{P}(u, a) = 0 , \\text{ in } D \\subset \\mathbb{R}^d,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "u = g ,  \\text{ in } \\partial D.\n",
    "\\end{equation}\n",
    "\n",
    "Here, $\\mathcal{P}$ is a Partial Differential Operator, $a$ are the coefficients/parameters and $u$ is the PDE solution.\n",
    "\n",
    "In the FNO framework, the surrogate ML model is given by a the solution operator $\\mathcal{G}^\\dagger_{\\theta}$, which maps any given coefficient in the coefficient space $a$ to the solution $u$. The FNO is trained in a supervised fashion using training data in the form of input-output pairs $\\lbrace a_j, u_j \\rbrace_{j = 1}^N$. The training loss for the FNO is given by summing the data loss, $\\mathcal{L}_{data}(\\mathcal{G}_\\theta) = \\lVert u - \\mathcal{G}_\\theta(a)  \\rVert^2$ over all training pairs $\\lbrace a_i, u_i,  \\rbrace_{i=1}^N$,\n",
    "\n",
    "In the PINO framework, the solution operator is optimized with an additional PDE loss given by $\\mathcal{L}_{pde}(a, \\mathcal{G}_{\\theta}(a))$ computed over i.i.d. samples $a_j$ from an appropriate supported distribution in parameter/coefficient space.\n",
    "\n",
    "In general, the PDE loss involves computing the PDE operator which in turn involves computing the partial derivatives of the Fourier Neural Operator ansatz. In general this is nontrivial. The key set of innovations in the PINO are the various ways to compute the partial derivatives of the operator ansatz. The PINO framework implements the differentiation in four different ways.\n",
    "\n",
    "1. Numerical differentiation using a Finite-Difference Method (FDM).\n",
    "2. Numerical differentiation computed via spectral derivative. \n",
    "3. Hybrid differentiation based on a combination of first-order \"exact\" derivatives and second-order FDM derivatives. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb1a06",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "This problem illustrates developing a surrogate model that learns the mapping between a permeability and pressure field of\n",
    "a Darcy flow system. The mapping learned, $\\textbf{K} \\rightarrow \\textbf{U}$, should be true for a distribution of permeability fields $\\textbf{K} \\sim p(\\textbf{K})$ and not just a single solution.\n",
    "\n",
    "The key difference between PINO and FNO is that PINO adds a physics-informed term to the loss function of FNO. As discussed further in the theory, the PINO loss function is described by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L} = \\mathcal{L}_{data} + \\mathcal{L}_{pde},\n",
    "\\end{equation}\n",
    "\n",
    "where,\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{data} = \\lVert u - \\mathcal{G}_\\theta(a)  \\rVert^2 ,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathcal{G}_\\theta(a)$ is a FNO model with learnable parameters $\\theta$ and input field $a$, and \n",
    "$\\mathcal{L}_{pde}$ is an appropriate PDE loss. For the 2D Darcy problem this is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{pde} = \\lVert -\\nabla \\cdot \\left(k(\\textbf{x})\\nabla \\mathcal{G}_\\theta(a)(\\textbf{x})\\right) - f(\\textbf{x}) \\rVert^2 ,\n",
    "\\end{equation}\n",
    "\n",
    "where $k(\\textbf{x})$ is the permeability field, $f(\\textbf{x})$ is the forcing function equal to 1 in this case, and $a=k$ in this case.\n",
    "\n",
    "Note that the PDE loss involves computing various partial derivatives of the FNO ansatz, $\\mathcal{G}_\\theta(a)$. \n",
    "In general this is nontrivial; in Modulus, three different methods for computing these are provided. These are based on the original PINO paper:\n",
    "\n",
    "1. Numerical differentiation computed via Finite-Difference Method (FDM)\n",
    "2. Numerical differentiation computed via spectral derivative\n",
    "3. Hybrid differentiation based on a combination of first-order \"exact\" derivatives and second-order FDM derivatives\n",
    "\n",
    "The first 2 approaches are the same as proposed in the original paper. The third approach is a modification of the \"exact\" approach proposed in the paper.\n",
    "This method is slower and more memory intensive than the numerical derivative approaches when computing second order derivatives\n",
    "because it requires the computation of a Hessian matrix. \n",
    "Instead, a \"hybrid\" approach is provided which offers a compromise by combining first-order \"exact\"(the exact method is not technically exact because it uses a combination of numerical spectral derivatives and exact differentiation, see original paper for more details) derivatives and second-order FDM derivatives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d60419",
   "metadata": {},
   "source": [
    "## Case setup\n",
    "\n",
    "The setup for this problem is largely the same as the FNO example, except that the PDE loss is defined and the FNO model is constrained using it. This process is described in detail when we define the PDE loss. \n",
    "\n",
    "Similar to the FNO notebook, the training and validation data for this example can be found on the [Fourier Neural Operator Github page](https://github.com/zongyi-li/fourier_neural_operator). The data can be downloaded using an automated script similar to the FNO notebook. \n",
    "\n",
    "**Note:** In this notebook we will walk through the contents of [`darcy_PINO.py`](../../source_code/darcy/darcy_PINO.py) script. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbfce4",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The configuration for this problem is similar to the FNO example, but importantly there is an extra parameter `custom.gradient_method` where the method for computing the gradients in the PDE loss is selected. This can be one of `fdm`, `fourier`, `hybrid` corresponding to the three options above. The balance between the data and PDE terms in the loss function can also be controlled using the `loss.weights` parameter group. The contents of the [`config_PINO.yaml`](../../source_code/darcy/conf/config_PINO.yaml) are shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13806720",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - /arch/conv_fully_connected_cfg@arch.decoder\n",
    "  - /arch/fno_cfg@arch.fno\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "cuda_graphs: false\n",
    "jit: false\n",
    "\n",
    "custom:\n",
    "  gradient_method: hybrid\n",
    "  ntrain: 1000\n",
    "  ntest: 100\n",
    "\n",
    "arch:\n",
    "  decoder:\n",
    "    input_keys: [z, 32]\n",
    "    output_keys: sol\n",
    "    nr_layers: 1\n",
    "    layer_size: 32\n",
    "\n",
    "  fno:\n",
    "    input_keys: coeff\n",
    "    dimension: 2\n",
    "    nr_fno_layers: 4\n",
    "    fno_modes: 12\n",
    "    padding: 9\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 1000\n",
    "\n",
    "training:\n",
    "  rec_results_freq : 1000\n",
    "  max_steps : 10000\n",
    "\n",
    "loss:\n",
    "  weights:\n",
    "    sol: 1.0\n",
    "    darcy: 0.1\n",
    "\n",
    "batch_size:\n",
    "  grid: 8\n",
    "  validation: 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a97e6e",
   "metadata": {},
   "source": [
    "## Define PDE Loss for grid data\n",
    "\n",
    "For this example, a custom PDE residual calculation is defined using the various approaches proposed above. The process of defining a custom PDE residual using sympy and auto-diff was discussed in the [notebooks on PINNs](../diffusion_1d/Diffusion_Problem_Notebook.ipynb). For this problem, we will not be relying on standard auto-diff for calculating the derivatives, instead we want to explicitly define how the residual is calculated using a custom `torch.nn.Module` called `Darcy`. The purpose of this module is to compute and return the Darcy PDE residual given the input and output tensors of the FNO model, which is done via its `.forward(...)` method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887393c",
   "metadata": {},
   "source": [
    "```python\n",
    "# helper function for computing spectral derivatives\n",
    "from modulus.models.layers.spectral_layers import fourier_derivatives \n",
    "# helper function for computing finite difference derivatives\n",
    "from ops import dx, ddx \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f604e1",
   "metadata": {},
   "source": [
    "```python\n",
    "class Darcy(torch.nn.Module):\n",
    "    \"Custom Darcy PDE definition for PINO\"\n",
    "\n",
    "    def __init__(self, gradient_method: str = \"hybrid\"):\n",
    "        super().__init__()\n",
    "        self.gradient_method = str(gradient_method)\n",
    "\n",
    "    def forward(self, input_var: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # get inputs\n",
    "        u = input_var[\"sol\"]\n",
    "        c = input_var[\"coeff\"]\n",
    "        dcdx = input_var[\"Kcoeff_y\"]  # data is reversed\n",
    "        dcdy = input_var[\"Kcoeff_x\"]\n",
    "\n",
    "        dxf = 1.0 / u.shape[-2]\n",
    "        dyf = 1.0 / u.shape[-1]\n",
    "        # Compute gradients based on method\n",
    "        # Exact first order and FDM second order\n",
    "        if self.gradient_method == \"hybrid\":\n",
    "            dudx_exact = input_var[\"sol__x\"]\n",
    "            dudy_exact = input_var[\"sol__y\"]\n",
    "            dduddx_fdm = input_var[\"sol__x__x\"]\n",
    "            dduddy_fdm = input_var[\"sol__y__y\"]\n",
    "            # compute darcy equation\n",
    "            darcy = (\n",
    "                1.0\n",
    "                + (dcdx * dudx_exact)\n",
    "                + (c * dduddx_fdm)\n",
    "                + (dcdy * dudy_exact)\n",
    "                + (c * dduddy_fdm)\n",
    "            )\n",
    "        # FDM gradients\n",
    "        elif self.gradient_method == \"fdm\":\n",
    "            dudx_fdm = dx(u, dx=dxf, channel=0, dim=0, order=1, padding=\"replication\")\n",
    "            dudy_fdm = dx(u, dx=dyf, channel=0, dim=1, order=1, padding=\"replication\")\n",
    "            dduddx_fdm = ddx(\n",
    "                u, dx=dxf, channel=0, dim=0, order=1, padding=\"replication\"\n",
    "            )\n",
    "            dduddy_fdm = ddx(\n",
    "                u, dx=dyf, channel=0, dim=1, order=1, padding=\"replication\"\n",
    "            )\n",
    "            # compute darcy equation\n",
    "            darcy = (\n",
    "                1.0\n",
    "                + (dcdx * dudx_fdm)\n",
    "                + (c * dduddx_fdm)\n",
    "                + (dcdy * dudy_fdm)\n",
    "                + (c * dduddy_fdm)\n",
    "            )\n",
    "        # Fourier derivative\n",
    "        elif self.gradient_method == \"fourier\":\n",
    "            dim_u_x = u.shape[2]\n",
    "            dim_u_y = u.shape[3]\n",
    "            u = F.pad(\n",
    "                u, (0, dim_u_y - 1, 0, dim_u_x - 1), mode=\"reflect\"\n",
    "            )  # Constant seems to give best results\n",
    "            f_du, f_ddu = fourier_derivatives(u, [2.0, 2.0])\n",
    "            dudx_fourier = f_du[:, 0:1, :dim_u_x, :dim_u_y]\n",
    "            dudy_fourier = f_du[:, 1:2, :dim_u_x, :dim_u_y]\n",
    "            dduddx_fourier = f_ddu[:, 0:1, :dim_u_x, :dim_u_y]\n",
    "            dduddy_fourier = f_ddu[:, 1:2, :dim_u_x, :dim_u_y]\n",
    "            # compute darcy equation\n",
    "            darcy = (\n",
    "                1.0\n",
    "                + (dcdx * dudx_fourier)\n",
    "                + (c * dduddx_fourier)\n",
    "                + (dcdy * dudy_fourier)\n",
    "                + (c * dduddy_fourier)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Derivative method {self.gradient_method} not supported.\")\n",
    "\n",
    "        # Zero outer boundary\n",
    "        darcy = F.pad(darcy[:, :, 2:-2, 2:-2], [2, 2, 2, 2], \"constant\", 0)\n",
    "        # Return darcy\n",
    "        output_var = {\n",
    "            \"darcy\": dxf * darcy,\n",
    "        }  # weight boundary loss higher\n",
    "        return output_var\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6cda2",
   "metadata": {},
   "source": [
    "The gradients of the FNO solution are computed according to the gradient method selected above. The FNO model automatically outputs first order gradients when the `hybrid` method is used, and so no extra computation of these is necessary. Furthermore, note that the gradients of the permeability field are already included as tensors in the FNO input training data (with keys `Kcoeff_x` and `Kcoeff_y`) and so these do not need to be computed.\n",
    "\n",
    "Next, incorporate this module into Modulus by wrapping it into a Modulus `Node`. This ensures the module is incorporated into Modulusâ€™ computational graph and can be used to optimise the FNO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399a615",
   "metadata": {},
   "source": [
    "```python\n",
    "from modulus.node import Node\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43a66c",
   "metadata": {},
   "source": [
    "```python\n",
    "    # Make custom Darcy residual node for PINO\n",
    "    inputs = [\n",
    "        \"sol\",\n",
    "        \"coeff\",\n",
    "        \"Kcoeff_x\",\n",
    "        \"Kcoeff_y\",\n",
    "    ]\n",
    "    if cfg.custom.gradient_method == \"hybrid\":\n",
    "        inputs += [\n",
    "            \"sol__x\",\n",
    "            \"sol__y\",\n",
    "        ]\n",
    "    darcy_node = Node(\n",
    "        inputs=inputs,\n",
    "        outputs=[\"darcy\"],\n",
    "        evaluate=Darcy(gradient_method=cfg.custom.gradient_method),\n",
    "        name=\"Darcy Node\",\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216e17d",
   "metadata": {},
   "source": [
    "## Loading the Data and Initializing the Model\n",
    "\n",
    "These sections follow similar processes as the FNO example. Only for the case where `hybrid` gradient method is used, you need to additionally instruct the model to output the appropriate gradients by specifying these gradients in its output keys. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a81c32",
   "metadata": {},
   "source": [
    "```python\n",
    "    # load training/ test data\n",
    "    input_keys = [\n",
    "        Key(\"coeff\", scale=(7.48360e00, 4.49996e00)),\n",
    "        Key(\"Kcoeff_x\"),\n",
    "        Key(\"Kcoeff_y\"),\n",
    "    ]\n",
    "    output_keys = [\n",
    "        Key(\"sol\", scale=(5.74634e-03, 3.88433e-03)),\n",
    "    ]\n",
    "\n",
    "    download_FNO_dataset(\"Darcy_241\", outdir=\"datasets/\")\n",
    "    invar_train, outvar_train = load_FNO_dataset(\n",
    "        \"datasets/Darcy_241/piececonst_r241_N1024_smooth1.hdf5\",\n",
    "        [k.name for k in input_keys],\n",
    "        [k.name for k in output_keys],\n",
    "        n_examples=cfg.custom.ntrain,\n",
    "    )\n",
    "    invar_test, outvar_test = load_FNO_dataset(\n",
    "        \"datasets/Darcy_241/piececonst_r241_N1024_smooth2.hdf5\",\n",
    "        [k.name for k in input_keys],\n",
    "        [k.name for k in output_keys],\n",
    "        n_examples=cfg.custom.ntest,\n",
    "    )\n",
    "\n",
    "    # add additional constraining values for darcy variable\n",
    "    outvar_train[\"darcy\"] = np.zeros_like(outvar_train[\"sol\"])\n",
    "\n",
    "    train_dataset = DictGridDataset(invar_train, outvar_train)\n",
    "    test_dataset = DictGridDataset(invar_test, outvar_test)\n",
    "\n",
    "    # Define FNO model\n",
    "    decoder_net = instantiate_arch(\n",
    "        cfg=cfg.arch.decoder,\n",
    "        output_keys=output_keys,\n",
    "    )\n",
    "    fno = instantiate_arch(\n",
    "        cfg=cfg.arch.fno,\n",
    "        input_keys=[input_keys[0]],\n",
    "        decoder_net=decoder_net,\n",
    "    )\n",
    "    if cfg.custom.gradient_method == \"hybrid\":\n",
    "        derivatives = [\n",
    "            Key(\"sol\", derivatives=[Key(\"x\")]),\n",
    "            Key(\"sol\", derivatives=[Key(\"y\")]),\n",
    "            Key(\"sol\", derivatives=[Key(\"x\"), Key(\"x\")]),\n",
    "            Key(\"sol\", derivatives=[Key(\"y\"), Key(\"y\")]),\n",
    "        ]\n",
    "        fno.add_pino_gradients(\n",
    "            derivatives=derivatives,\n",
    "            domain_length=[1.0, 1.0],\n",
    "        )\n",
    "\n",
    "    # Make custom Darcy residual node for PINO\n",
    "    inputs = [\n",
    "        \"sol\",\n",
    "        \"coeff\",\n",
    "        \"Kcoeff_x\",\n",
    "        \"Kcoeff_y\",\n",
    "    ]\n",
    "    if cfg.custom.gradient_method == \"hybrid\":\n",
    "        inputs += [\n",
    "            \"sol__x\",\n",
    "            \"sol__y\",\n",
    "        ]\n",
    "    darcy_node = Node(\n",
    "        inputs=inputs,\n",
    "        outputs=[\"darcy\"],\n",
    "        evaluate=Darcy(gradient_method=cfg.custom.gradient_method),\n",
    "        name=\"Darcy Node\",\n",
    "    )\n",
    "    nodes = [fno.make_node('fno'), darcy_node]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed602b",
   "metadata": {},
   "source": [
    "## Adding Constraints\n",
    "\n",
    "Finally, add constraints to your model in a similar fashion to the FNO example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4818573",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain\n",
    "    domain = Domain()\n",
    "\n",
    "    # add constraints to domain\n",
    "    supervised = SupervisedGridConstraint(\n",
    "        nodes=nodes,\n",
    "        dataset=train_dataset,\n",
    "        batch_size=cfg.batch_size.grid,\n",
    "    )\n",
    "    domain.add_constraint(supervised, \"supervised\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a40ab4",
   "metadata": {},
   "source": [
    "The process of defining the validator and using the `Solver` class remains the same as the FNO example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b517e",
   "metadata": {},
   "source": [
    "## Training the Model \n",
    "\n",
    "The training can now be simply started by executing the python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff2f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5733c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../../source_code/darcy/darcy_PINO.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4988e",
   "metadata": {},
   "source": [
    "## Results and Post-processing\n",
    "\n",
    "The network directory folder contains several plots of different validation predictions. One of them is shown below.\n",
    "\n",
    "PINO validation predictions. (Left to right) Input permeability and its spatial derivatives, true pressure, predicted pressure, error.\n",
    "\n",
    "<img src=\"pino_darcy_pred.png\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a5d3e",
   "metadata": {},
   "source": [
    "### Comparison to FNO\n",
    "\n",
    "The Tensorboard plot below compares the validation loss of PINO (all three gradient methods) and FNO. You can see that with large amounts of training data (1000 training examples), both FNO and PINO perform similarly. \n",
    "\n",
    "<img src=\"pino_darcy_tensorboard1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "A benefit of PINO is that the PDE loss regularizes the model, meaning that it can be more efficient in \"small data\" regimes. The plot below shows the validation loss when both models are trained with only 100 training examples. In this case, we find that PINO outperforms FNO. \n",
    "\n",
    "<img src=\"pino_darcy_tensorboard2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085924b",
   "metadata": {},
   "source": [
    "# Licensing\n",
    "This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
